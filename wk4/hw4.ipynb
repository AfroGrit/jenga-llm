{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data/results-gpt4o-mini.csv'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df = pd.read_csv(docs_url)\n",
    "\n",
    "# docs_response = requests.get(docs_url)\n",
    "# documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:300]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name='multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "llm = df.iloc[0].answer_llm\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = embedding_model.encode(llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model\n",
    "\n",
    "Now, get the embeddings model `multi-qa-mpnet-base-dot-v1` from\n",
    "[the Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)\n",
    "\n",
    "> Note: this is not the same model as in HW3\n",
    "\n",
    "```bash\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "```\n",
    "\n",
    "Create the embeddings for the first LLM answer:\n",
    "\n",
    "```python\n",
    "answer_llm = df.iloc[0].answer_llm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244655"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_llm     You can sign up for the course by visiting the...\n",
       "answer_orig    Machine Learning Zoomcamp FAQ\\nThe purpose of ...\n",
       "document                                                0227b872\n",
       "question                     Where can I sign up for the course?\n",
       "course                                 machine-learning-zoomcamp\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing answers:   0%|          | 1/300 [00:00<01:54,  2.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing answers: 100%|██████████| 300/300 [02:22<00:00,  2.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17.515987,\n",
       " 13.418402,\n",
       " 25.313255,\n",
       " 12.147415,\n",
       " 18.747736,\n",
       " 33.970406,\n",
       " 30.251705,\n",
       " 29.521576,\n",
       " 35.272198,\n",
       " 27.751772,\n",
       " 32.34471,\n",
       " 31.441843,\n",
       " 36.38072,\n",
       " 33.340504,\n",
       " 30.606163,\n",
       " 32.503044,\n",
       " 29.67445,\n",
       " 24.35346,\n",
       " 20.13247,\n",
       " 23.99548,\n",
       " 30.88028,\n",
       " 32.692436,\n",
       " 30.049173,\n",
       " 16.078167,\n",
       " 31.79642,\n",
       " 37.980003,\n",
       " 20.839046,\n",
       " 32.612865,\n",
       " 38.894196,\n",
       " 34.051826,\n",
       " 28.263878,\n",
       " 27.124832,\n",
       " 23.975264,\n",
       " 26.340149,\n",
       " 18.658115,\n",
       " 25.016403,\n",
       " 21.101131,\n",
       " 33.72679,\n",
       " 29.340347,\n",
       " 28.654505,\n",
       " 29.608585,\n",
       " 30.810738,\n",
       " 33.331203,\n",
       " 26.220482,\n",
       " 26.550072,\n",
       " 13.148597,\n",
       " 12.962547,\n",
       " 12.275609,\n",
       " 9.9744425,\n",
       " 10.883928,\n",
       " 29.845068,\n",
       " 32.36178,\n",
       " 22.18718,\n",
       " 30.268936,\n",
       " 25.091877,\n",
       " 32.742783,\n",
       " 28.220984,\n",
       " 27.274975,\n",
       " 24.208645,\n",
       " 22.568907,\n",
       " 19.767456,\n",
       " 18.679333,\n",
       " 20.422321,\n",
       " 22.051325,\n",
       " 18.188013,\n",
       " 28.455883,\n",
       " 25.919708,\n",
       " 23.33234,\n",
       " 22.20594,\n",
       " 28.296299,\n",
       " 39.23055,\n",
       " 36.758507,\n",
       " 31.913895,\n",
       " 31.202858,\n",
       " 36.913048,\n",
       " 30.514185,\n",
       " 36.26145,\n",
       " 27.397552,\n",
       " 37.792786,\n",
       " 23.29768,\n",
       " 34.252586,\n",
       " 34.550625,\n",
       " 30.316462,\n",
       " 35.703526,\n",
       " 31.012535,\n",
       " 35.45961,\n",
       " 35.075775,\n",
       " 35.429832,\n",
       " 29.88118,\n",
       " 30.037102,\n",
       " 31.247982,\n",
       " 29.893936,\n",
       " 28.52552,\n",
       " 31.754606,\n",
       " 32.590054,\n",
       " 39.476013,\n",
       " 34.973713,\n",
       " 28.725079,\n",
       " 30.6841,\n",
       " 37.264107,\n",
       " 35.62684,\n",
       " 33.20293,\n",
       " 25.320389,\n",
       " 32.18891,\n",
       " 22.518667,\n",
       " 30.810648,\n",
       " 37.47419,\n",
       " 27.127544,\n",
       " 27.558437,\n",
       " 33.077446,\n",
       " 25.819035,\n",
       " 35.047577,\n",
       " 34.910126,\n",
       " 35.86292,\n",
       " 35.66461,\n",
       " 23.890953,\n",
       " 26.650803,\n",
       " 19.036322,\n",
       " 23.732624,\n",
       " 36.686493,\n",
       " 23.63226,\n",
       " 26.224371,\n",
       " 28.33199,\n",
       " 28.205893,\n",
       " 29.783947,\n",
       " 27.14346,\n",
       " 14.99993,\n",
       " 18.169998,\n",
       " 18.22865,\n",
       " 20.363134,\n",
       " 5.448559,\n",
       " 5.9324837,\n",
       " 7.8709774,\n",
       " 4.5479236,\n",
       " 5.3850884,\n",
       " 27.713974,\n",
       " 20.700142,\n",
       " 27.32947,\n",
       " 16.532589,\n",
       " 19.901363,\n",
       " 31.073881,\n",
       " 29.637468,\n",
       " 28.450895,\n",
       " 24.889114,\n",
       " 26.597538,\n",
       " 26.66406,\n",
       " 33.77531,\n",
       " 28.765789,\n",
       " 19.707878,\n",
       " 17.306507,\n",
       " 34.357475,\n",
       " 30.77972,\n",
       " 30.170502,\n",
       " 27.354593,\n",
       " 32.209934,\n",
       " 26.88023,\n",
       " 28.167719,\n",
       " 29.97623,\n",
       " 28.072683,\n",
       " 31.957582,\n",
       " 30.330576,\n",
       " 29.305614,\n",
       " 27.504326,\n",
       " 27.409874,\n",
       " 26.012468,\n",
       " 31.341295,\n",
       " 29.248137,\n",
       " 34.054386,\n",
       " 29.529325,\n",
       " 27.144749,\n",
       " 26.034883,\n",
       " 31.496738,\n",
       " 32.259842,\n",
       " 21.932491,\n",
       " 30.880066,\n",
       " 39.092705,\n",
       " 32.142105,\n",
       " 25.345892,\n",
       " 23.97759,\n",
       " 27.314085,\n",
       " 30.877428,\n",
       " 28.470518,\n",
       " 28.86775,\n",
       " 28.173199,\n",
       " 27.834404,\n",
       " 33.211494,\n",
       " 27.782207,\n",
       " 28.150196,\n",
       " 27.548817,\n",
       " 29.624222,\n",
       " 28.466618,\n",
       " 27.704882,\n",
       " 27.517042,\n",
       " 26.017357,\n",
       " 16.815935,\n",
       " 29.181885,\n",
       " 30.130192,\n",
       " 27.39175,\n",
       " 28.571144,\n",
       " 21.44202,\n",
       " 29.071888,\n",
       " 27.17482,\n",
       " 26.663845,\n",
       " 26.1534,\n",
       " 29.61127,\n",
       " 27.712765,\n",
       " 17.301193,\n",
       " 25.073748,\n",
       " 26.105179,\n",
       " 15.056329,\n",
       " 32.22444,\n",
       " 26.998756,\n",
       " 24.001854,\n",
       " 30.299423,\n",
       " 31.251945,\n",
       " 24.931465,\n",
       " 27.136263,\n",
       " 20.048164,\n",
       " 22.204573,\n",
       " 18.398666,\n",
       " 23.471607,\n",
       " 23.656586,\n",
       " 20.096876,\n",
       " 27.785181,\n",
       " 23.721886,\n",
       " 29.476564,\n",
       " 31.923637,\n",
       " 27.786558,\n",
       " 25.282497,\n",
       " 21.090363,\n",
       " 34.241966,\n",
       " 34.566086,\n",
       " 35.93257,\n",
       " 22.799612,\n",
       " 33.241444,\n",
       " 19.981956,\n",
       " 22.636581,\n",
       " 24.13118,\n",
       " 23.120184,\n",
       " 11.905029,\n",
       " 32.21834,\n",
       " 29.581188,\n",
       " 22.277004,\n",
       " 26.25491,\n",
       " 18.278994,\n",
       " 33.623146,\n",
       " 29.776497,\n",
       " 30.866934,\n",
       " 26.53907,\n",
       " 26.438847,\n",
       " 23.820007,\n",
       " 27.36067,\n",
       " 29.63708,\n",
       " 31.316284,\n",
       " 20.207516,\n",
       " 34.52057,\n",
       " 33.354908,\n",
       " 28.47409,\n",
       " 27.694311,\n",
       " 21.486217,\n",
       " 29.003836,\n",
       " 26.534304,\n",
       " 28.948309,\n",
       " 27.005241,\n",
       " 24.34091,\n",
       " 21.60849,\n",
       " 33.209816,\n",
       " 31.647543,\n",
       " 30.631369,\n",
       " 25.525118,\n",
       " 31.80574,\n",
       " 34.976173,\n",
       " 29.75033,\n",
       " 28.02201,\n",
       " 24.982292,\n",
       " 34.441284,\n",
       " 33.40549,\n",
       " 30.952467,\n",
       " 25.195036,\n",
       " 29.613964,\n",
       " 31.487982,\n",
       " 29.713963,\n",
       " 28.341751,\n",
       " 28.797338,\n",
       " 28.471727,\n",
       " 38.855072,\n",
       " 35.33558,\n",
       " 13.904609,\n",
       " 38.24656,\n",
       " 30.029465,\n",
       " 33.363068,\n",
       " 25.712193,\n",
       " 32.535797,\n",
       " 31.41125,\n",
       " 30.524261,\n",
       " 34.001778,\n",
       " 33.69086,\n",
       " 34.491524,\n",
       " 27.538357,\n",
       " 18.414108]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "evaluations=[]\n",
    "\n",
    "# for elem in df.iterrows():\n",
    "for _, elem in tqdm(df.iterrows(), total=len(df), desc=\"Processing answers\"):\n",
    "    answer_orig = elem['answer_orig'] \n",
    "    answer_llm = elem['answer_llm'] \n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "\n",
    "    evaluations.append(v_llm.dot(v_orig))\n",
    "\n",
    "evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing the dot product\n",
    "\n",
    "- Now for each answer pair, let's create embeddings and compute dot product between them\n",
    "- We will put the results (scores) into the `evaluations` list\n",
    "- What's the 75% percentile of the score?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 75th percentile of the scores is: 31.6743\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 75th percentile\n",
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "\n",
    "print(f\"The 75th percentile of the scores is: {percentile_75:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing answers: 100%|██████████| 300/300 [02:22<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def normalize(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    v_norm = v / norm\n",
    "    return v_norm\n",
    "\n",
    "evaluations_norm=[]\n",
    "\n",
    "# for elem in df.iterrows():\n",
    "for _, elem in tqdm(df.iterrows(), total=len(df), desc=\"Processing answers\"):\n",
    "    answer_orig = elem['answer_orig'] \n",
    "    answer_llm = elem['answer_llm'] \n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "    v_llm_norm = normalize(v_llm)\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "    v_orig_norm =  normalize(v_orig)\n",
    "    evaluations_norm.append(v_llm_norm.dot(v_orig_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5067539,\n",
       " 0.38854873,\n",
       " 0.7185989,\n",
       " 0.33726627,\n",
       " 0.5217923,\n",
       " 0.83053213,\n",
       " 0.7462835,\n",
       " 0.6944061,\n",
       " 0.84688616,\n",
       " 0.65590763,\n",
       " 0.7779559,\n",
       " 0.78356636,\n",
       " 0.90468806,\n",
       " 0.80630296,\n",
       " 0.72759616,\n",
       " 0.7751896,\n",
       " 0.71516633,\n",
       " 0.5890557,\n",
       " 0.53322953,\n",
       " 0.5857593,\n",
       " 0.81232715,\n",
       " 0.83714426,\n",
       " 0.76611555,\n",
       " 0.43333992,\n",
       " 0.81558585,\n",
       " 0.92667866,\n",
       " 0.552616,\n",
       " 0.7622108,\n",
       " 0.9452982,\n",
       " 0.8478371,\n",
       " 0.7192839,\n",
       " 0.6864791,\n",
       " 0.6100939,\n",
       " 0.64910805,\n",
       " 0.48555,\n",
       " 0.6549567,\n",
       " 0.52971876,\n",
       " 0.84890294,\n",
       " 0.73956215,\n",
       " 0.76096815,\n",
       " 0.70153177,\n",
       " 0.7140965,\n",
       " 0.77817,\n",
       " 0.6202106,\n",
       " 0.62210196,\n",
       " 0.33472955,\n",
       " 0.3324926,\n",
       " 0.31343076,\n",
       " 0.25845352,\n",
       " 0.27644622,\n",
       " 0.77109647,\n",
       " 0.89201,\n",
       " 0.5712719,\n",
       " 0.7779895,\n",
       " 0.7033882,\n",
       " 0.8988763,\n",
       " 0.7822658,\n",
       " 0.69761264,\n",
       " 0.6318737,\n",
       " 0.5829771,\n",
       " 0.59635806,\n",
       " 0.5221753,\n",
       " 0.5993201,\n",
       " 0.65132016,\n",
       " 0.53131604,\n",
       " 0.761606,\n",
       " 0.6682948,\n",
       " 0.6511333,\n",
       " 0.66239053,\n",
       " 0.75467545,\n",
       " 0.89955723,\n",
       " 0.87245953,\n",
       " 0.75394404,\n",
       " 0.7211681,\n",
       " 0.8531313,\n",
       " 0.74570763,\n",
       " 0.85769904,\n",
       " 0.6625385,\n",
       " 0.91524327,\n",
       " 0.55959284,\n",
       " 0.8276353,\n",
       " 0.8465157,\n",
       " 0.74230355,\n",
       " 0.8715825,\n",
       " 0.7529516,\n",
       " 0.8018651,\n",
       " 0.8231076,\n",
       " 0.8007548,\n",
       " 0.68041277,\n",
       " 0.6951716,\n",
       " 0.8961544,\n",
       " 0.83714855,\n",
       " 0.8057662,\n",
       " 0.9236039,\n",
       " 0.9143867,\n",
       " 0.9000191,\n",
       " 0.81219006,\n",
       " 0.67952967,\n",
       " 0.6867199,\n",
       " 0.8579356,\n",
       " 0.87433946,\n",
       " 0.7897507,\n",
       " 0.6058619,\n",
       " 0.7653111,\n",
       " 0.6195592,\n",
       " 0.737174,\n",
       " 0.8384352,\n",
       " 0.61083513,\n",
       " 0.6532676,\n",
       " 0.7258446,\n",
       " 0.6543803,\n",
       " 0.92430544,\n",
       " 0.9337149,\n",
       " 0.9587959,\n",
       " 0.9345276,\n",
       " 0.6309589,\n",
       " 0.72350216,\n",
       " 0.48164386,\n",
       " 0.62675816,\n",
       " 0.918337,\n",
       " 0.6905621,\n",
       " 0.7319256,\n",
       " 0.7669854,\n",
       " 0.775046,\n",
       " 0.8219246,\n",
       " 0.73368186,\n",
       " 0.36580613,\n",
       " 0.4729826,\n",
       " 0.5297904,\n",
       " 0.5278301,\n",
       " 0.15033378,\n",
       " 0.16259554,\n",
       " 0.22896065,\n",
       " 0.12535672,\n",
       " 0.14907657,\n",
       " 0.8608228,\n",
       " 0.6495168,\n",
       " 0.8210608,\n",
       " 0.49092087,\n",
       " 0.53667176,\n",
       " 0.8139329,\n",
       " 0.83326244,\n",
       " 0.75782573,\n",
       " 0.6944205,\n",
       " 0.75459105,\n",
       " 0.686602,\n",
       " 0.7933617,\n",
       " 0.682746,\n",
       " 0.48471823,\n",
       " 0.4068992,\n",
       " 0.9168881,\n",
       " 0.8109052,\n",
       " 0.7576652,\n",
       " 0.6902132,\n",
       " 0.8495096,\n",
       " 0.78858113,\n",
       " 0.8231363,\n",
       " 0.8638776,\n",
       " 0.80344486,\n",
       " 0.9195234,\n",
       " 0.91087186,\n",
       " 0.87111634,\n",
       " 0.7844466,\n",
       " 0.8046905,\n",
       " 0.7555795,\n",
       " 0.8136051,\n",
       " 0.73089814,\n",
       " 0.84138554,\n",
       " 0.7769921,\n",
       " 0.6778061,\n",
       " 0.76621705,\n",
       " 0.79355013,\n",
       " 0.84841573,\n",
       " 0.6082472,\n",
       " 0.82088995,\n",
       " 0.906824,\n",
       " 0.8077607,\n",
       " 0.65071183,\n",
       " 0.6042328,\n",
       " 0.70193446,\n",
       " 0.80505127,\n",
       " 0.737492,\n",
       " 0.75319993,\n",
       " 0.72830737,\n",
       " 0.6678438,\n",
       " 0.8697071,\n",
       " 0.7675075,\n",
       " 0.7556013,\n",
       " 0.7391145,\n",
       " 0.82990426,\n",
       " 0.9263626,\n",
       " 0.8851108,\n",
       " 0.8814405,\n",
       " 0.8279311,\n",
       " 0.54172164,\n",
       " 0.7976832,\n",
       " 0.82603365,\n",
       " 0.7654161,\n",
       " 0.76598245,\n",
       " 0.5675457,\n",
       " 0.7969284,\n",
       " 0.7953675,\n",
       " 0.80033827,\n",
       " 0.72718334,\n",
       " 0.8399166,\n",
       " 0.8905327,\n",
       " 0.5133375,\n",
       " 0.80328774,\n",
       " 0.8810312,\n",
       " 0.4662354,\n",
       " 0.9119289,\n",
       " 0.7465079,\n",
       " 0.6021073,\n",
       " 0.8736125,\n",
       " 0.8359318,\n",
       " 0.72718275,\n",
       " 0.8083547,\n",
       " 0.54849803,\n",
       " 0.63815355,\n",
       " 0.5346819,\n",
       " 0.7306878,\n",
       " 0.7561727,\n",
       " 0.5733434,\n",
       " 0.8801695,\n",
       " 0.7715907,\n",
       " 0.86457,\n",
       " 0.9356905,\n",
       " 0.8134221,\n",
       " 0.8004232,\n",
       " 0.6286988,\n",
       " 0.878125,\n",
       " 0.8817501,\n",
       " 0.91531885,\n",
       " 0.6066896,\n",
       " 0.85126615,\n",
       " 0.6370443,\n",
       " 0.77223945,\n",
       " 0.78330004,\n",
       " 0.7464661,\n",
       " 0.36829734,\n",
       " 0.90070516,\n",
       " 0.8165291,\n",
       " 0.5891101,\n",
       " 0.71645844,\n",
       " 0.5433668,\n",
       " 0.9083933,\n",
       " 0.7886219,\n",
       " 0.8092998,\n",
       " 0.72053677,\n",
       " 0.76923025,\n",
       " 0.64836967,\n",
       " 0.68449163,\n",
       " 0.8168502,\n",
       " 0.8166458,\n",
       " 0.55176526,\n",
       " 0.8816926,\n",
       " 0.86099637,\n",
       " 0.723094,\n",
       " 0.64812124,\n",
       " 0.50445664,\n",
       " 0.82624143,\n",
       " 0.7752443,\n",
       " 0.81286955,\n",
       " 0.74823487,\n",
       " 0.74998397,\n",
       " 0.58051455,\n",
       " 0.846388,\n",
       " 0.7909031,\n",
       " 0.75424886,\n",
       " 0.6786619,\n",
       " 0.8744372,\n",
       " 0.90543103,\n",
       " 0.8081237,\n",
       " 0.77691114,\n",
       " 0.639755,\n",
       " 0.868979,\n",
       " 0.8800772,\n",
       " 0.82116234,\n",
       " 0.67354435,\n",
       " 0.72401196,\n",
       " 0.9038982,\n",
       " 0.86243504,\n",
       " 0.8033401,\n",
       " 0.8227595,\n",
       " 0.8054043,\n",
       " 0.95774,\n",
       " 0.8829242,\n",
       " 0.3415635,\n",
       " 0.9483267,\n",
       " 0.754716,\n",
       " 0.92996335,\n",
       " 0.69955224,\n",
       " 0.86588347,\n",
       " 0.891375,\n",
       " 0.80319023,\n",
       " 0.91417503,\n",
       " 0.90218973,\n",
       " 0.9047338,\n",
       " 0.7267817,\n",
       " 0.49389875]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Computing the cosine\n",
    "\n",
    "From Q2, we can see that the results are not within the [0, 1] range. It's because the vectors coming from this model are not normalized.\n",
    "\n",
    "So we need to normalize them.\n",
    "\n",
    "To do it, we \n",
    "\n",
    "* Compute the norm of a vector\n",
    "* Divide each element by this norm\n",
    "\n",
    "So, for vector `v`, it'll be `v / ||v||`\n",
    "\n",
    "In numpy, this is how you do it:\n",
    "\n",
    "```python\n",
    "norm = np.sqrt((v * v).sum())\n",
    "v_norm = v / norm\n",
    "```\n",
    "\n",
    "Let's put it into a function and then compute dot product \n",
    "between normalized vectors. This will give us cosine similarity\n",
    "\n",
    "What's the 75% cosine in the scores?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 75th percentile of the scores is: 0.8362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "percentile_75_norm = np.percentile(evaluations_norm, 75)\n",
    "\n",
    "print(f\"The 75th percentile of the scores is: {percentile_75_norm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "\n",
    "# try one\n",
    "\n",
    "# Get the specific row from the dataframe\n",
    "r = df.loc[df['document'] == '5170565b'].iloc[0]\n",
    "\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Rouge\n",
    "\n",
    "Now we will explore an alternative metric - the ROUGE score.  \n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:\n",
    "\n",
    "```bash\n",
    "pip install rouge\n",
    "```\n",
    "\n",
    "(The latest version at the moment of writing is `1.0.1`)\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (`doc_id=5170565b`)\n",
    "\n",
    "```\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "```\n",
    "\n",
    "There are three scores: `rouge-1`, `rouge-2` and `rouge-l`, and precision, recall and F1 score for each.\n",
    "\n",
    "* `rouge-1` - the overlap of unigrams,\n",
    "* `rouge-2` - bigrams,\n",
    "* `rouge-l` - the longest common subsequence\n",
    "\n",
    "What's the F score for `rouge-1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q5. Average rouge score\n",
    "\n",
    "Let's compute the average F-score between `rouge-1`, `rouge-2` and `rouge-l` for the same record from Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-scores:\n",
      "  ROUGE-1: 0.1795\n",
      "  ROUGE-2: 0.0235\n",
      "  ROUGE-L: 0.1538\n",
      "\n",
      "Average F-score: 0.1190\n"
     ]
    }
   ],
   "source": [
    "# Extract F-scores for ROUGE-1, ROUGE-2, and ROUGE-L\n",
    "f_score_1 = scores['rouge-1']['f']\n",
    "f_score_2 = scores['rouge-2']['f']\n",
    "f_score_l = scores['rouge-l']['f']\n",
    "\n",
    "# Compute the average F-score\n",
    "average_f_score = (f_score_1 + f_score_2 + f_score_l) / 3\n",
    "\n",
    "print(f\"F-scores:\")\n",
    "print(f\"  ROUGE-1: {f_score_1:.4f}\")\n",
    "print(f\"  ROUGE-2: {f_score_2:.4f}\")\n",
    "print(f\"  ROUGE-L: {f_score_l:.4f}\")\n",
    "print(f\"\\nAverage F-score: {average_f_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Average rouge score for all the data points\n",
    "\n",
    "Now let's compute the F-score for all the records and create a dataframe from them.\n",
    "\n",
    "What's the average F-score in `rouge_2` across all the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ROUGE scores:  35%|███▍      | 104/300 [00:00<00:00, 420.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ROUGE scores: 100%|██████████| 300/300 [00:01<00:00, 298.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ROUGE-2 F-score across all records is: 0.2070\n",
      "\n",
      "First few rows of the ROUGE scores dataframe:\n",
      "   document  rouge_1_f  rouge_2_f  rouge_l_f\n",
      "0  0227b872   0.095238   0.028169   0.095238\n",
      "1  0227b872   0.125000   0.055556   0.093750\n",
      "2  0227b872   0.415584   0.177778   0.389610\n",
      "3  0227b872   0.216216   0.047059   0.189189\n",
      "4  0227b872   0.142076   0.033898   0.120219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare lists to store the scores\n",
    "rouge_scores = []\n",
    "\n",
    "# Compute ROUGE scores for each record\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Computing ROUGE scores\"):\n",
    "    scores = rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]\n",
    "    \n",
    "    rouge_scores.append({\n",
    "        'document': row['document'],\n",
    "        'rouge_1_f': scores['rouge-1']['f'],\n",
    "        'rouge_2_f': scores['rouge-2']['f'],\n",
    "        'rouge_l_f': scores['rouge-l']['f']\n",
    "    })\n",
    "\n",
    "# Create a new dataframe with the scores\n",
    "rouge_df = pd.DataFrame(rouge_scores)\n",
    "\n",
    "# Calculate the average ROUGE-2 score\n",
    "average_rouge_2 = rouge_df['rouge_2_f'].mean()\n",
    "\n",
    "print(f\"The average ROUGE-2 F-score across all records is: {average_rouge_2:.4f}\")\n",
    "\n",
    "# Display the first few rows of the new dataframe\n",
    "print(\"\\nFirst few rows of the ROUGE scores dataframe:\")\n",
    "print(rouge_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20696501983423318"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rouge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
